{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "import pickle\n",
    "from collections import deque\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.externals import joblib\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleTracker:\n",
    "    def __init__(self):\n",
    "        # classifier\n",
    "        self.data = joblib.load('clf_scaler.p')\n",
    "        self.X_scaler = self.data['scaler']\n",
    "        self.svc = self.data['clf']\n",
    "        # HOG parameters\n",
    "        self.color_space = 'YUV'\n",
    "        self.orient = 24\n",
    "        self.pix_per_cell = 16\n",
    "        self.cell_per_block = 2\n",
    "        self.channel = 0\n",
    "        # 64x64 windows\n",
    "        self.y_start_small = 400\n",
    "        self.y_stop_small = 528\n",
    "        self.scale_small = 1.0\n",
    "        # 96x96 windows\n",
    "        self.y_start_med = 400\n",
    "        self.y_stop_med = 592\n",
    "        self.scale_med = 1.5\n",
    "        # 128x128 windows\n",
    "        self.y_start_big = 404\n",
    "        self.y_stop_big = 660\n",
    "        self.scale_big = 2.0\n",
    "        # buffer\n",
    "        self.all_windows = []\n",
    "\n",
    "    def convert_color(self, img, conv):\n",
    "        color = 'cv2.COLOR_RGB2{}'.format(conv)\n",
    "        color = eval(color)\n",
    "        return cv2.cvtColor(img, color)\n",
    "\n",
    "    def find_cars(self, img, ystart, ystop, scale):    \n",
    "        img_tosearch = img[ystart:ystop,:,:]\n",
    "        ctrans_tosearch = self.convert_color(img_tosearch, self.color_space)\n",
    "        # resize in order to fit in 64x64 patches (because clf was trained that way)\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "            \n",
    "        ch = ctrans_tosearch[:,:,self.channel]\n",
    "        \n",
    "        # compute HOG features for the image\n",
    "        hog_features = hog(ch, self.orient, (self.pix_per_cell, self.pix_per_cell),\n",
    "                           (self.cell_per_block, self.cell_per_block),\n",
    "                           transform_sqrt=True, feature_vector=False)\n",
    "\n",
    "        # define blocks and steps\n",
    "        nxblocks = (ctrans_tosearch.shape[1] // self.pix_per_cell) - self.cell_per_block + 1\n",
    "        nyblocks = (ctrans_tosearch.shape[0] // self.pix_per_cell) - self.cell_per_block + 1 \n",
    "\n",
    "        window = 64 # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        nblocks_per_window = (window // self.pix_per_cell) - self.cell_per_block + 1\n",
    "        cells_per_step = 2\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        windows_list = []\n",
    "\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb * cells_per_step\n",
    "                xpos = xb * cells_per_step\n",
    "                # extract HOG for this patch\n",
    "                hog_feat = hog_features[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                \n",
    "                xleft = xpos * self.pix_per_cell\n",
    "                ytop = ypos * self.pix_per_cell\n",
    "                \n",
    "                # get features for classifier and predict\n",
    "                features = self.X_scaler.transform(hog_feat.reshape(1, -1)) \n",
    "                prediction = self.svc.predict(features)\n",
    "\n",
    "                if prediction:\n",
    "                    xwindow_left = np.int(xleft*scale)\n",
    "                    ytop_left = np.int(ytop*scale)\n",
    "                    length = np.int(window*scale)\n",
    "                    windows_list.append(((xwindow_left, ytop_left+ystart), \n",
    "                                         (xwindow_left+length, ytop_left+length+ystart)))\n",
    "        return windows_list\n",
    "\n",
    "    def add_heat(self, heatmap, box_list):\n",
    "        for i, box in enumerate(box_list):\n",
    "            # add 1 for all pixels inside each box\n",
    "            # parameter 'i' defines weight of a box \n",
    "            # so newer boxes have more impact\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 0.1*i\n",
    "        return heatmap\n",
    "\n",
    "    def heat_threshold(self, heatmap, threshold=2):\n",
    "        # zero out pixels below the threshold\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        return heatmap\n",
    "    \n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        # iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (255, 255, 0), 6)\n",
    "        return img\n",
    "    \n",
    "    def vehicle_tracking(self, img):\n",
    "        # search windows 64x64, 96x96 and 128x128\n",
    "        windows_small = self.find_cars(img, self.y_start_small, self.y_stop_small, self.scale_small)\n",
    "        windows_med = self.find_cars(img, self.y_start_med, self.y_stop_med, self.scale_med)\n",
    "        windows_big = self.find_cars(img, self.y_start_big, self.y_stop_big, self.scale_big)\n",
    "        windows = windows_small + windows_med + windows_big                    \n",
    "        \n",
    "        # if something found\n",
    "        if len(windows) > 0:\n",
    "            self.all_windows.append(windows)\n",
    "            # wait for a few first frames to get more detections\n",
    "            if len(self.all_windows) >= 5:\n",
    "                heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "                list_windows = [window for sublist in self.all_windows for window in sublist]\n",
    "                heat = self.add_heat(heat, list_windows)\n",
    "                heat = self.heat_threshold(heat, 1+int(len(list_windows)*1.7)) \n",
    "                heatmap = np.clip(heat, 0, 255)\n",
    "                labels = label(heatmap)\n",
    "                result = self.draw_labeled_bboxes(np.copy(img), labels)\n",
    "                # keep size of buffer from growing (no more than 18 frames)\n",
    "                if len(self.all_windows) > 18:\n",
    "                    self.all_windows.pop(0)\n",
    "                return result\n",
    "        elif len(self.all_windows) > 0:\n",
    "            self.all_windows.pop(0)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaneTracker:\n",
    "    def __init__(self):\n",
    "        # load calibration parameters\n",
    "        self.coeffs = pickle.load(open('coeffs.p', 'rb'))\n",
    "        self.mtx = self.coeffs['mtx']\n",
    "        self.dist = self.coeffs['dist']\n",
    "        # transform points\n",
    "        self.s_pts = np.array(((550, 480), (740, 480), (1110, 720), (200, 720)), np.float32)\n",
    "        self.d_pts = np.array(((300, 0), (1000, 0), (1000, 720), (300, 720)), np.float32)\n",
    "        self.M = cv2.getPerspectiveTransform(self.s_pts, self.d_pts)\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.d_pts, self.s_pts)\n",
    "        # line coeffs to check parallel left/right\n",
    "        self.a2 = 0.0003\n",
    "        self.b2 = 0.35\n",
    "        self.c2 = (370, 820)\n",
    "        # margin for searching lines on next frame\n",
    "        self.margin_find = 40\n",
    "        self.margin_check = 100\n",
    "        # minimum number of pixels found to recenter window\n",
    "        self.minpix = 50\n",
    "        # buffer\n",
    "        self.buffer_left_coeffs = deque(maxlen=5)\n",
    "        self.buffer_right_coeffs = deque(maxlen=5)\n",
    "        # tracking lines\n",
    "        self.detected = False\n",
    "    \n",
    "    def undistort(self, img):\n",
    "        return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "\n",
    "    def warp(self, img, M):\n",
    "        # add contrast correction\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        img[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_YUV2RGB)\n",
    "        return cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    def magnitude(self, img, sobel_kernel, thresh):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        mag = np.sqrt(abs_sobelx**2 + abs_sobely**2)\n",
    "        scaled_mag = np.uint8(255 * mag / np.max(mag))\n",
    "        binary = np.zeros_like(scaled_mag)\n",
    "        binary[scaled_mag >= thresh] = 1\n",
    "        return binary\n",
    "\n",
    "    # color\n",
    "    def color_thresh(self, img):\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        L = lab[:,:,0]\n",
    "        B = lab[:,:,2]\n",
    "        B = cv2.morphologyEx(B, cv2.MORPH_TOPHAT, np.ones((25,25),np.uint8))\n",
    "        thresh_b = (5, 100)\n",
    "        thresh_l = (245, 255)\n",
    "        color = np.zeros_like(L)\n",
    "        cond1 = (L > thresh_l[0]) & (L <= thresh_l[1])\n",
    "        cond2 = (B > thresh_b[0]) & (B <= thresh_b[1])\n",
    "        color[cond1 | cond2] = 1\n",
    "        return color\n",
    "    \n",
    "    def apply_colorgrad(self, img):     \n",
    "        grad = self.magnitude(img, sobel_kernel=15, thresh=50)\n",
    "        color = self.color_thresh(img)\n",
    "        combined = np.zeros_like(grad)\n",
    "        combined[(color == 1) | (grad == 1)] = 1\n",
    "        combined = cv2.erode(combined, np.ones((7,7),np.uint8), iterations=1)\n",
    "        return combined\n",
    "\n",
    "    # fit lines\n",
    "    def find_line(self, img, side, window_height=80):\n",
    "        # take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "        # find the starting point for the left and right lines\n",
    "        midpoint = histogram.shape[0] // 2\n",
    "        \n",
    "        if side == 'left':\n",
    "            x_initial = np.argmax(histogram[:midpoint])\n",
    "        if side == 'right':\n",
    "            x_initial = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        nwindows = img.shape[0] // window_height\n",
    "\n",
    "        # identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzeroy = np.array(img.nonzero()[0])\n",
    "        nonzerox = np.array(img.nonzero()[1])\n",
    "        # current positions to be updated for each window\n",
    "        x_current = x_initial\n",
    "                \n",
    "        lane_inds = []\n",
    "        for window in range(nwindows):\n",
    "            # window boundaries in x and y (and right and left)\n",
    "            win_y_low = img.shape[0] - (window + 1) * window_height\n",
    "            win_y_high = img.shape[0] - window * window_height\n",
    "            win_x_low = x_current - self.margin_find\n",
    "            win_x_high = x_current + self.margin_find\n",
    "            # identify the nonzero pixels in x and y within the window\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "            lane_inds.append(good_inds)\n",
    "            \n",
    "            # if found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_inds) > self.minpix:\n",
    "                x_current = np.int(np.mean(nonzerox[good_inds]))\n",
    "            \n",
    "        lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "        # extract left and right line pixel positions\n",
    "        x = nonzerox[lane_inds]\n",
    "        y = nonzeroy[lane_inds] \n",
    "        \n",
    "        # fit a second order polynomial to each\n",
    "        coeffs = None\n",
    "        if x.any() is not None:\n",
    "            try:\n",
    "                coeffs = np.polyfit(y, x, 2)\n",
    "            except:\n",
    "                return None\n",
    "        return coeffs\n",
    "    \n",
    "    def search_margin(self, bnr, cfs, side):\n",
    "        y = np.array(bnr.nonzero()[0])\n",
    "        x = np.array(bnr.nonzero()[1])\n",
    "                \n",
    "        lane_inds = ((x > (cfs[0]*(y**2) + cfs[1]*y + cfs[2] - self.margin_check)) & \n",
    "                     (x < (cfs[0]*(y**2) + cfs[1]*y + cfs[2] + self.margin_check))) \n",
    "\n",
    "        # extract left and right line pixel positions\n",
    "        x = x[lane_inds]\n",
    "        y = y[lane_inds] \n",
    "        # fit a second order polynomial to each\n",
    "        coeffs = None\n",
    "                        \n",
    "        if x.all() is not None:\n",
    "            try:\n",
    "                coeffs = np.polyfit(y, x, 2)\n",
    "            except:\n",
    "                return None\n",
    "        return coeffs\n",
    "                \n",
    "    def parallel_left_right(self, left_coeffs, right_coeffs):\n",
    "        diff = np.absolute(left_coeffs - right_coeffs)\n",
    "        if diff[0] < self.a2 and diff[1] < self.b2 and diff[2] > self.c2[0] and diff[2] < self.c2[1]:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def create_line(self, shape, coeffs):\n",
    "        ploty = np.linspace(0, shape[0]-1, shape[0])\n",
    "        line = coeffs[0]*ploty**2 + coeffs[1]*ploty + coeffs[2]\n",
    "        return line\n",
    "    \n",
    "    def draw_back(self, img, b, left, right):\n",
    "        warp_zero = np.zeros_like(b).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "        # recast the x and y points into usable format for cv2.fillPoly()\n",
    "        ploty = np.linspace(0, b.shape[0]-1, b.shape[0])\n",
    "        pts_left = np.array([np.transpose(np.vstack([left, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        # draw the lane onto the warped blank image\n",
    "        pts = np.int_([pts])\n",
    "        cv2.fillPoly(color_warp, pts, (0, 255, 0))\n",
    "        \n",
    "        # warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, self.Minv, (img.shape[1], img.shape[0]))         \n",
    "        return newwarp\n",
    "    \n",
    "    def pipeline(self, img):\n",
    "        copy = np.copy(img)\n",
    "        und = self.undistort(copy)\n",
    "        wrp = self.warp(und, self.M)\n",
    "        bnr = self.apply_colorgrad(wrp)\n",
    "        \n",
    "        lft_coeffs = None\n",
    "        rght_coeffs = None\n",
    "        lft_line = None\n",
    "        rght_line = None\n",
    "        \n",
    "        # find lines coeffs\n",
    "        if not self.detected:\n",
    "            lft_coeffs = self.find_line(bnr, 'left')\n",
    "            rght_coeffs = self.find_line(bnr, 'right')     \n",
    "        else:\n",
    "            lft_coeffs_prev = self.buffer_left_coeffs[-1]\n",
    "            lft_coeffs = self.search_margin(bnr, lft_coeffs_prev, 'left')\n",
    "            rght_coeffs_prev = self.buffer_right_coeffs[-1]\n",
    "            rght_coeffs = self.search_margin(bnr, rght_coeffs_prev, 'right')\n",
    "        \n",
    "        # check if parallel left and right\n",
    "        if lft_coeffs is not None and rght_coeffs is not None:\n",
    "            if self.parallel_left_right(lft_coeffs, rght_coeffs):\n",
    "                if len(self.buffer_left_coeffs) > 0 and len(self.buffer_right_coeffs) > 0:\n",
    "                    self.buffer_left_coeffs.append(lft_coeffs)\n",
    "                    self.buffer_right_coeffs.append(rght_coeffs)\n",
    "                    lft_coeffs = np.average(self.buffer_left_coeffs, axis=0, \n",
    "                                            weights=range(len(self.buffer_left_coeffs),0,-1))\n",
    "                    rght_coeffs = np.average(self.buffer_right_coeffs, axis=0, \n",
    "                                             weights=range(len(self.buffer_right_coeffs),0,-1))\n",
    "                lft_line = self.create_line(bnr.shape, lft_coeffs)\n",
    "                rght_line = self.create_line(bnr.shape, rght_coeffs)\n",
    "                self.detected = True\n",
    "            else:\n",
    "                lft_coeffs = None\n",
    "                rght_coeffs = None\n",
    "        \n",
    "        # check left/right side\n",
    "        if lft_line is not None and rght_line is not None:\n",
    "            mid = bnr.shape[1] / 2\n",
    "            if lft_line[-1] > mid or rght_line[-1] < mid:\n",
    "                lft_coeffs = None\n",
    "                rght_coeffs = None\n",
    "                lft_line = None\n",
    "                rght_line = None\n",
    "                self.buffer_left_coeffs = self.buffer_left_coeffs[:-1]\n",
    "                self.buffer_right_coeffs = self.buffer_right_coeffs[:-1]\n",
    "                self.detected = False\n",
    "                \n",
    "        # if not found, use buffer\n",
    "        if lft_coeffs is None and rght_coeffs is None:\n",
    "            if len(self.buffer_left_coeffs) > 0 and len(self.buffer_right_coeffs) > 0:\n",
    "                lft_coeffs = np.average(self.buffer_left_coeffs, axis=0, \n",
    "                                        weights=range(len(self.buffer_left_coeffs),0,-1))\n",
    "                rght_coeffs = np.average(self.buffer_right_coeffs, axis=0, \n",
    "                                        weights=range(len(self.buffer_right_coeffs),0,-1))\n",
    "                lft_line = self.create_line(bnr.shape, lft_coeffs)  \n",
    "                rght_line = self.create_line(bnr.shape, rght_coeffs)\n",
    "                self.detected = False\n",
    "        \n",
    "        # draw and update\n",
    "        if lft_coeffs is not None and rght_coeffs is not None:\n",
    "            img = self.draw_back(img, bnr, lft_line, rght_line)\n",
    "        if self.detected:\n",
    "            self.buffer_left_coeffs.append(lft_coeffs)\n",
    "            self.buffer_right_coeffs.append(rght_coeffs)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_tracker = VehicleTracker()\n",
    "lane_tracker = LaneTracker()\n",
    "\n",
    "def vehicle_and_lane(img):\n",
    "    vehicle = vehicle_tracker.vehicle_tracking(np.copy(img))\n",
    "    lane = lane_tracker.pipeline(np.copy(img))\n",
    "    # combine vehicle detection and lane finding\n",
    "    return cv2.addWeighted(vehicle, 1, lane, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video videos_output/out_video.mp4\n",
      "[MoviePy] Writing video videos_output/out_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [07:10<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: videos_output/out_video.mp4 \n",
      "\n",
      "CPU times: user 8min 40s, sys: 16.5 s, total: 8min 56s\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "test_vid_out_name = 'videos_output/out_video.mp4'\n",
    "test_clip = VideoFileClip('project_video.mp4')#.subclip(5,35)\n",
    "test_out_clip = test_clip.fl_image(vehicle_and_lane)\n",
    "%time test_out_clip.write_videofile(test_vid_out_name, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
